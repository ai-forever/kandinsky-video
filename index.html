<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Kandinsky Video</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/video-camera.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Kandinsky Video </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Vladimir Arkhipkin</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Zein Shaheen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="hhttps://ai-forever.github.io/kandinsky-video/">Viacheslav Vasilev</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Elizaveta Dakhova</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Andrey Kuznetsov</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Denis Dimitrov</a><sup>1,</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Sber AI,</span>
            <span class="author-block"><sup>2</sup>Moscow Institute of Physics and Technology</span>
            <span class="author-block"><sup>3</sup>Artificial Intelligence Research Institute</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ai-forever.github.io/kandinsky-video/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://ai-forever.github.io/kandinsky-video/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ai-forever/KandinskyVideo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/meduza.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fireplace.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/explosion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/road.mp4"
                    type="video/mp4">
          </video>
        </div>  
      </div>
    </div> -->
    <img src="./static/images/title.JPG"
    class="interpolation-image"
    alt="Interpolate start reference image."/>

    <p class="subtitle has-text-centered">
      Kandinsky Video is a text-to-video generation model consisting of two main stages - keyframe generation and interpolation. 
      <br> Our approach for temporal conditioning allows us to generate videos with high-quality appearance, smoothness and dynamics.
    </p>
  </div>
</section>

<!-- FusionFrames is a text-to-video generation model consisting of two main stages - keyframe generation and interpolation.  -->
<!-- Our approach for temporal conditioning allows us to generate videos with high-quality appearance, smoothness and dynamics. -->
<!--  -->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimedia generation approaches occupy a prominent
place in artificial intelligence research. Text-to-image mod-
els achieved high-quality results over the last few years.
However, video synthesis methods recently started to de-
velop. This paper presents a new two-stage latent diffusion
text-to-video generation architecture based on the text-to-
image diffusion model. The first stage concerns keyframes
synthesis to figure the storyline of a video, while the second
one is devoted to interpolation frames generation to make
movements of the scene and objects smooth. We compare
several temporal conditioning approaches for keyframes
generation. The results show the advantage of using sep-
arate temporal blocks over temporal layers in terms of met-
rics reflecting video generation quality aspects and human
preference. The design of our interpolation model sig-
nificantly reduces computational costs compared to other
masked frame interpolation approaches. Furthermore, we
evaluate different configurations of MoVQ-based video de-
coding scheme to improve consistency and achieve higher
PSNR, SSIM, MSE, and LPIPS scores. Finally, we com-
pare our pipeline with existing solutions and achieve top-
2 scores overall and top-1 among open-source solutions:
CLIPSIM = 0.2976 and FVD = 433.054. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overall Pipeline</h2>
        <div class="content has-text-justified">
          <img src="./static/images/pipeline.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <p>
            The encoded text prompt enters the U-Net keyframe generation model with temporal layers or blocks, and then the sampled latent keyframes are  sent to the latent interpolation model in such a way as to predict three interpolation frames between two keyframes. A temporal MoVQ-GAN decoder is used to get the final video result.
          </p>
        </div>
      </div>    
    </div>
    <!--/ Matting. -->

      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Keyframes Generation with Temporal Conditioning </h2>
          <div class="content has-text-justified">
            <img src="./static/images/temporal_layers_blocks.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <p>
            We examined two approaches of temporal components use in pretrained architecture of T2I U-Net â€“ the traditional approach of mixing spatial and temporal layers in one block (left) and our approach of allocating a separate temporal block (middle). 
            All layers indicated in gray are not trained in T2V architectures and are initialized with the weights of the T2I model. 
            NA and N in the left corner of all layers correspond to the presence of prenormalization layers with and without activation, respectively. 
            For different types of blocks we implemented different types of temporal attention and temporal convolution layers, (left). 
            We also implement different types of temporal conditioning. One of them is simple conditioning when pixel see only itself value in different moments of type (1D layers). 
            In 3D layers pixels can see the values of its neighbors also in different moments of time (right).
          </p>
          </div>
        </div>    
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Video Frame Interpolation</h2>
          <div class="content has-text-justified">
            <img src="./static/images/interpolation_ours.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <p>
            A summary of the primary changes made to the T2I architecture includes: 
            (i) The input convolution now accepts three noisy latent inputs (interpolated frames) and two conditioning latent inputs (keyframes). 
            (ii) The output convolution predicts three denoised latents.
             (iii) Temporal convolutions have been introduced after each spatial convolution.

          </p>
          </div>
        </div>    
      </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results for temporal conditioning</h2>
        <div class="content has-text-justified">
        
        <img src="./static/images/panda_generations.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          
        <p>
          We propose our approach for temporal conditioning based on separate temporal blocks. 
          We compared three types of temporal blocks with temporal layers, which were commonly used in previous works, and gained the advantage of our approach in terms of frame quality, text alignment and temporal consistency.
        </p>
        
        <div class="container">
          <h3>Comparison</h3>
          <table class="center">
              <tbody><tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/Meerkat_conv_attn_blocks_1d.gif" raw="true"></td>
                <td><img src="./static/videos/Meerkat_conv_attn_blocks_3dattn.gif"></td>
                <td><img src="./static/videos/Meerkat_conv_attn_blocks_3dconv.gif"></td>              
                <td><img src="./static/videos/Meerkat_conv_attn_layers_1d.gif"></td>
              </tr>
            </tbody>
            </table>
        </div>
        
        </div>
      </div>    
    </div>
  </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Other results</h2>
        <div class="content has-text-justified">
          <div class="hero-body">  
            <table class="center">
              <tbody><tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/A car moving on the road from the sea to the mountains.gif" raw="true"></td>
                <td><img src="./static/videos/A red car drifting, 4k video.gif"></td>
                <td><img src="./static/videos/chemistry laboratory, chemical explosion, 4k.gif"></td>              
                <td><img src="./static/videos/Erupting volcano_ raw power, molten lava, and the forces of the Earth.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"A car moving on the road from the sea to the mountains"</td>
                <td width="25%" style="text-align:center;">"A red car drifting, 4k video</td>
                <td width="25%" style="text-align:center;">"Chemistry laboratory, chemical explosion, 4k"</td>
                <td width="25%" style="text-align:center;">"Erupting volcano raw power, molten lava, and the forces of the Earth"</td>
              </tr>
              <tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/luminescent jellyfish swims underwater, neon, 4k.gif" raw="true"></td>
                <td><img src="./static/videos/Majestic waterfalls in a lush rainforest_ power, mist, and biodiversity.gif"></td>
                <td><img src="./static/videos/white ghost flies through a night clearing, 4k.gif"></td>              
                <td><img src="./static/videos/Wildlife migration_ herds on the move, crossing landscapes in harmony.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"Luminescent jellyfish swims underwater, neon, 4k"</td>
                <td width="25%" style="text-align:center;">"Majestic waterfalls in a lush rainforest power, mist, and biodiversity</td>
                <td width="25%" style="text-align:center;">"White ghost flies through a night clearing, 4k.gif""</td>
                <td width="25%" style="text-align:center;">"Wildlife migration herds on the move, crossing landscapes in harmony"</td>
              </tr>
              <tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/Majestic humpback whale breaching_ power, grace, and ocean spectacle.gif" raw="true"></td>
                <td><img src="./static/videos/Evoke the sense of wonder in a time-lapse journey through changing seasons.gif"></td>
                <td><img src="./static/videos/Explore the fascinating world of underwater creatures in a visually stunning sequence.gif"></td>              
                <td><img src="./static/videos/Polar ice caps_ the pristine wilderness of the Arctic and Antarctic.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"Majestic humpback whale breaching_ power, grace, and ocean spectacle"</td>
                <td width="25%" style="text-align:center;">"Evoke the sense of wonder in a time-lapse journey through changing seasons</td>
                <td width="25%" style="text-align:center;">"Explore the fascinating world of underwater creatures in a visually stunning sequence"</td>
                <td width="25%" style="text-align:center;">"Polar ice caps the pristine wilderness of the Arctic and Antarctic"</td>
              </tr>
              <tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/Rolling waves on a sandy beach_ relaxation, rhythm, and coastal beauty.gif" raw="true"></td>
                <td><img src="./static/videos/Sloth in slow motion_ deliberate movements, relaxation, and arboreal life.gif"></td>
                <td><img src="./static/videos/Sunrise over a tranquil mountain landscape_ colors, serenity, and awakening.gif"></td>              
                <td><img src="./static/videos/Craft a heartwarming narrative showcasing the bond between a human and their loyal pet companion.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"Rolling waves on a sandy beach_ relaxation, rhythm, and coastal beauty"</td>
                <td width="25%" style="text-align:center;">"Sloth in slow motion_ deliberate movements, relaxation, and arboreal life</td>
                <td width="25%" style="text-align:center;">"Sunrise over a tranquil mountain landscape colors, serenity, and awakening"</td>
                <td width="25%" style="text-align:center;">"Craft a heartwarming narrative showcasing the bond between a human and their loyal pet companion"</td>
              </tr>
            </tbody></table>
        </div>
      </div>    
    </div>

</section>

<hr>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{TBD,
  author    = {TBD},
  title     = {TBD},
  journal   = {TBD},
  year      = {2023},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
